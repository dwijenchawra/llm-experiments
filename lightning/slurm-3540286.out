Run 'mamba init' to be able to run mamba activate/deactivate
and start a new shell session. Or use conda to activate/deactivate.

slurmstepd: error: TMPDIR [/tmp] is not writeable
slurmstepd: error: Setting TMPDIR to /tmp
Found cached dataset yelp_review_full (/home/dchawra/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf)
Found cached dataset yelp_review_full (/home/dchawra/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf)
Found cached dataset yelp_review_full (/home/dchawra/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf)
Found cached dataset yelp_review_full (/home/dchawra/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf)

  0%|          | 0/2 [00:00<?, ?it/s]
 50%|█████     | 1/2 [00:00<00:00,  1.57it/s]
100%|██████████| 2/2 [00:00<00:00,  2.86it/s]

  0%|          | 0/2 [00:00<?, ?it/s]
 50%|█████     | 1/2 [00:00<00:00,  2.47it/s]
100%|██████████| 2/2 [00:00<00:00,  4.28it/s]

  0%|          | 0/2 [00:00<?, ?it/s]
 50%|█████     | 1/2 [00:00<00:00,  1.25it/s]
100%|██████████| 2/2 [00:00<00:00,  2.33it/s]

  0%|          | 0/2 [00:00<?, ?it/s]
 50%|█████     | 1/2 [00:00<00:00,  1.44it/s]
100%|██████████| 2/2 [00:00<00:00,  2.66it/s]
Loading cached processed dataset at /home/dchawra/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-e32803c982b49825.arrow
Loading cached processed dataset at /home/dchawra/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-e32803c982b49825.arrow
Loading cached processed dataset at /home/dchawra/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-e32803c982b49825.arrow
Loading cached processed dataset at /home/dchawra/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-e32803c982b49825.arrow
Loading cached processed dataset at /home/dchawra/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-662755f5fd75c75b.arrow
Loading cached processed dataset at /home/dchawra/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-662755f5fd75c75b.arrow
Loading cached shuffled indices for dataset at /home/dchawra/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-bb837e48dfdd511e.arrow
Loading cached shuffled indices for dataset at /home/dchawra/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-bb837e48dfdd511e.arrow
Loading cached shuffled indices for dataset at /home/dchawra/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-ca03854e5be0dac2.arrow
Loading cached shuffled indices for dataset at /home/dchawra/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-ca03854e5be0dac2.arrow
Loading cached processed dataset at /home/dchawra/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-662755f5fd75c75b.arrow
Loading cached processed dataset at /home/dchawra/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-662755f5fd75c75b.arrow
Loading cached shuffled indices for dataset at /home/dchawra/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-bb837e48dfdd511e.arrow
Loading cached shuffled indices for dataset at /home/dchawra/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-bb837e48dfdd511e.arrow
Loading cached shuffled indices for dataset at /home/dchawra/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-ca03854e5be0dac2.arrow
Loading cached shuffled indices for dataset at /home/dchawra/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-ca03854e5be0dac2.arrow
Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
╭───────────────────── Traceback (most recent call last) ──────────────────────╮
│ /home/dchawra/llm_training/llm-experiments/lightning/multnodetest.py:53 in   │
│ <module>                                                                     │
│                                                                              │
│   50 │   # hyperparams = parser.parse_args()                                 │
│   51 │                                                                       │
│   52 │   # TRAIN                                                             │
│ ❱ 53 │   main()                                                              │
│   54                                                                         │
│                                                                              │
│ /home/dchawra/llm_training/llm-experiments/lightning/multnodetest.py:39 in   │
│ main                                                                         │
│                                                                              │
│   36 def main():                                                             │
│   37 │   model = AutoModelForSequenceClassification.from_pretrained("bert-ba │
│   38 │                                                                       │
│ ❱ 39 │   trainer = Trainer(                                                  │
│   40 │   │   gpus=8,                                                         │
│   41 │   │   num_nodes=4,                                                    │
│   42 │   │   accelerator='ddp'                                               │
╰──────────────────────────────────────────────────────────────────────────────╯
TypeError: Trainer.__init__() got an unexpected keyword argument 'gpus'
Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
╭───────────────────── Traceback (most recent call last) ──────────────────────╮
│ /home/dchawra/llm_training/llm-experiments/lightning/multnodetest.py:53 in   │
│ <module>                                                                     │
│                                                                              │
│   50 │   # hyperparams = parser.parse_args()                                 │
│   51 │                                                                       │
│   52 │   # TRAIN                                                             │
│ ❱ 53 │   main()                                                              │
│   54                                                                         │
│                                                                              │
│ /home/dchawra/llm_training/llm-experiments/lightning/multnodetest.py:39 in   │
│ main                                                                         │
│                                                                              │
│   36 def main():                                                             │
│   37 │   model = AutoModelForSequenceClassification.from_pretrained("bert-ba │
│   38 │                                                                       │
│ ❱ 39 │   trainer = Trainer(                                                  │
│   40 │   │   gpus=8,                                                         │
│   41 │   │   num_nodes=4,                                                    │
│   42 │   │   accelerator='ddp'                                               │
╰──────────────────────────────────────────────────────────────────────────────╯
TypeError: Trainer.__init__() got an unexpected keyword argument 'gpus'
Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']
- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
╭───────────────────── Traceback (most recent call last) ──────────────────────╮
│ /home/dchawra/llm_training/llm-experiments/lightning/multnodetest.py:53 in   │
│ <module>                                                                     │
│                                                                              │
│   50 │   # hyperparams = parser.parse_args()                                 │
│   51 │                                                                       │
│   52 │   # TRAIN                                                             │
│ ❱ 53 │   main()                                                              │
│   54                                                                         │
│                                                                              │
│ /home/dchawra/llm_training/llm-experiments/lightning/multnodetest.py:39 in   │
│ main                                                                         │
│                                                                              │
│   36 def main():                                                             │
│   37 │   model = AutoModelForSequenceClassification.from_pretrained("bert-ba │
│   38 │                                                                       │
│ ❱ 39 │   trainer = Trainer(                                                  │
│   40 │   │   gpus=8,                                                         │
│   41 │   │   num_nodes=4,                                                    │
│   42 │   │   accelerator='ddp'                                               │
╰──────────────────────────────────────────────────────────────────────────────╯
TypeError: Trainer.__init__() got an unexpected keyword argument 'gpus'
╭───────────────────── Traceback (most recent call last) ──────────────────────╮
│ /home/dchawra/llm_training/llm-experiments/lightning/multnodetest.py:53 in   │
│ <module>                                                                     │
│                                                                              │
│   50 │   # hyperparams = parser.parse_args()                                 │
│   51 │                                                                       │
│   52 │   # TRAIN                                                             │
│ ❱ 53 │   main()                                                              │
│   54                                                                         │
│                                                                              │
│ /home/dchawra/llm_training/llm-experiments/lightning/multnodetest.py:39 in   │
│ main                                                                         │
│                                                                              │
│   36 def main():                                                             │
│   37 │   model = AutoModelForSequenceClassification.from_pretrained("bert-ba │
│   38 │                                                                       │
│ ❱ 39 │   trainer = Trainer(                                                  │
│   40 │   │   gpus=8,                                                         │
│   41 │   │   num_nodes=4,                                                    │
│   42 │   │   accelerator='ddp'                                               │
╰──────────────────────────────────────────────────────────────────────────────╯
TypeError: Trainer.__init__() got an unexpected keyword argument 'gpus'
srun: error: gilbreth-k016: tasks 0-1: Exited with exit code 1
srun: error: gilbreth-k017: tasks 2-3: Exited with exit code 1
